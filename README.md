A Flask-based chatbot utilizing Ollama and the Deepseek model to generate more accurate AI responses. This project allows users to interact with the chatbot locally with easy deployment through Flask.

## üöÄ How to Run

### 1Ô∏è‚É£ Requirements

- Python 3.8 or newer
- Ollama installed and accessible from the terminal
- Git and pip installed

### 2Ô∏è‚É£ Clone the Repository

Run the following command in your terminal:

```sh
git clone https://github.com/username/flask-ollama-chatbot.git
cd flask-ollama-chatbot
```

### 3Ô∏è‚É£ Create a Virtual Environment

To avoid dependency conflicts, create a virtual environment:

```sh
python -m venv venv
```

Activate the virtual environment:

- **Mac/Linux**:
  ```sh
  source venv/bin/activate
  ```
- **Windows**:
  ```sh
  venv\Scripts\activate
  ```

### 4Ô∏è‚É£ Install Dependencies

Run the following command:

```sh
pip install -r requirements.txt
```

### 5Ô∏è‚É£ Run the Application

Once everything is installed, start the application:

```sh
flask run
```

Or alternatively:

```sh
python app.py
```

The application will run at: [http://127.0.0.1:5000](http://127.0.0.1:5000)

